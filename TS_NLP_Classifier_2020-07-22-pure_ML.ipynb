{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:55:44.910708Z",
     "start_time": "2020-08-17T13:55:44.232147Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pytesseract\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, f_classif\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_recall_fscore_support,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:55:44.973673Z",
     "start_time": "2020-08-17T13:55:44.911692Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_dataset(X, Y, test_size=0.3):\n",
    "    return train_test_split(\n",
    "        X, Y, test_size=test_size, random_state=42, shuffle=True, stratify=Y\n",
    "    )\n",
    "\n",
    "\n",
    "def save_vars(data, name):\n",
    "    with open(name, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "    return name\n",
    "\n",
    "\n",
    "def get_vars(pickle_file):\n",
    "    with open(pickle_file, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \" \".join(\n",
    "        char.lower()\n",
    "        for char in text.split()\n",
    "        if char.isalpha() and char != \"\" and len(char) > 2\n",
    "    )\n",
    "    return text\n",
    "\n",
    "\n",
    "def prepare_dataset(texts, classes):\n",
    "    y = []\n",
    "    x = []\n",
    "    for item in tqdm(texts):\n",
    "        if not item.endswith(\".txt\"):\n",
    "            continue\n",
    "        with open(item, \"r\") as f:\n",
    "            text = f.read()\n",
    "        text = clean_text(text)\n",
    "        short_name = os.path.basename(item)\n",
    "        name_without_ext = os.path.splitext(short_name)[0]\n",
    "        document_class = \"_\".join(name_without_ext.split(\"_\")[:-2])\n",
    "        if document_class not in classes:\n",
    "            document_class = \"unknown\"\n",
    "        y.append(classes.index(document_class))\n",
    "        x.append(text)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def balance_dataset(X, Y, document_classes, weights=None):\n",
    "    if weights is None:\n",
    "        weights = [1] * len(document_classes)\n",
    "    X_balanced = []\n",
    "    Y_balanced = []\n",
    "    min_frequency = min(Counter(Y).values())\n",
    "    for index, doc_class in enumerate(document_classes):\n",
    "        x, y = get_samples_of_type(\n",
    "            X, Y, index, document_classes, num=min_frequency * weights[index]\n",
    "        )\n",
    "        X_balanced += list(x)\n",
    "        Y_balanced += list(y)\n",
    "    return np.array(X_balanced), np.array(Y_balanced)\n",
    "\n",
    "\n",
    "def get_samples_of_type(documents, labels, document_type, classes, num=None):\n",
    "    print(f\"Processing {classes[document_type]}...\")\n",
    "    documents = np.array(documents)\n",
    "    labels = np.array(labels)\n",
    "    mask = np.where(labels == document_type)[0]\n",
    "    if num is not None:\n",
    "        mask = np.random.choice(mask, size=num)\n",
    "    documents_filtered = documents[mask]\n",
    "    labels_filtered = labels[mask]\n",
    "    return documents_filtered, labels_filtered\n",
    "\n",
    "\n",
    "def get_accuracy(document_type, model, type_dict, verbose=False):\n",
    "    x, y = type_dict.get(document_type, None)\n",
    "    predictions = model.predict(x)\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for predicted, true in zip(predictions, y):\n",
    "        total += 1\n",
    "        if predicted == true:\n",
    "            correct += 1\n",
    "    accuracy = round(correct / total, 3)\n",
    "    if verbose:\n",
    "        print(f\"Total: {total}\")\n",
    "        print(f\"Correct: {correct}\")\n",
    "        print(f\"Accuracy: {accuracy}\")\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def evaluate_models(models, model_names, document_names, verbose=False):\n",
    "    accuracies = []\n",
    "    for model in models:\n",
    "        model_accuracies = []\n",
    "        if verbose:\n",
    "            print(f\"Model: {model}\")\n",
    "        for key in type_dict:\n",
    "            if verbose:\n",
    "                print(f\"Document type: {key}\\n\")\n",
    "            accuracy = get_accuracy(key, model, type_dict)\n",
    "            model_accuracies.append(accuracy)\n",
    "        accuracies.append(model_accuracies)\n",
    "    df = pd.DataFrame(accuracies)\n",
    "    df.index = model_names\n",
    "    df.columns = document_names\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_confusion_matrix(model, features_test, labels_test, avg_method=\"micro\"):\n",
    "    prediction = model.predict(features_test)\n",
    "    print(\"Accuracy:\", accuracy_score(labels_test, prediction))\n",
    "    print(\"F1 score:\", f1_score(labels_test, prediction, average=avg_method))\n",
    "    print(\"Recall:\", recall_score(labels_test, prediction, average=avg_method))\n",
    "    print(\"Precision:\", precision_score(labels_test, prediction, average=avg_method))\n",
    "    print(\"\\n clasification report:\\n\", classification_report(labels_test, prediction))\n",
    "    print(\"\\n confussion matrix:\\n\", confusion_matrix(labels_test, prediction))\n",
    "\n",
    "\n",
    "def get_clf_results(grid_output, features_test, labels_test):\n",
    "    pipeline = grid_output.best_estimator_\n",
    "    build_confusion_matrix(pipeline, features_test, labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:55:45.002672Z",
     "start_time": "2020-08-17T13:55:44.974959Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_classifier(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    max_df_range=(0.5, 1),\n",
    "    min_df_range=(1, 10),\n",
    "    k_range=(1000, 10000),\n",
    "    clf=LinearSVC(),\n",
    "    ngram_max=2,\n",
    "    cv=5,\n",
    "):\n",
    "\n",
    "    epsilon = 0.0001\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    calibrated_clf = CalibratedClassifierCV(base_estimator=clf)\n",
    "    selector = SelectKBest(f_classif, k=10000)\n",
    "    param_grid = {\n",
    "        \"vect__max_df\": np.arange(max_df_range[0], max_df_range[1] + epsilon, 0.1),\n",
    "        \"select__k\": list(range(k_range[0], k_range[1] + 1, 2000)),\n",
    "        \"vect__ngram_range\": [(1, k) for k in range(2, ngram_max + 1)],\n",
    "        \"vect__min_df\": np.arange(min_df_range[0], min_df_range[1] + 1, 1),\n",
    "    }\n",
    "\n",
    "    if isinstance(clf, LinearSVC):\n",
    "        param_grid[\"clf__base_estimator__C\"] = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "    steps = [(\"vect\", vectorizer), (\"select\", selector), (\"clf\", calibrated_clf)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    grid = RandomizedSearchCV(\n",
    "        pipeline, cv=cv, param_distributions=param_grid, verbose=10, n_jobs=24\n",
    "    )\n",
    "    grid.fit(X_train, Y_train)\n",
    "    print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "    means = grid.cv_results_[\"mean_test_score\"]\n",
    "    stds = grid.cv_results_[\"std_test_score\"]\n",
    "    params = grid.cv_results_[\"params\"]\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(f\"Mean {round(mean,3)}+-{round(stdev,3)} and {param}\")\n",
    "    return grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:55:45.011363Z",
     "start_time": "2020-08-17T13:55:45.003645Z"
    }
   },
   "outputs": [],
   "source": [
    "CLASSES = [\n",
    "    \"commercial_invoice\",\n",
    "    \"packing_list\",\n",
    "    \"delivery_note\",\n",
    "    \"customs_summary_declaration_with_commercial_detail_export\",\n",
    "    \"despatch_note_model_t\",\n",
    "    \"unknown\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:55:45.366674Z",
     "start_time": "2020-08-17T13:55:45.012192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178513"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_path = os.path.join(os.getcwd(), \"all_texts\") \n",
    "texts = [os.path.join(texts_path, item) for item in os.listdir(texts_path)]\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data | `UNBALANCED`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:55:59.814663Z",
     "start_time": "2020-08-17T13:55:45.369198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a047d2e16885411aa8019554678e7d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=178513.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X, Y = prepare_dataset(texts, CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:55:59.846275Z",
     "start_time": "2020-08-17T13:55:59.822007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'delivery_note': 10877,\n",
       " 'customs_summary_declaration_with_commercial_detail_export': 38814,\n",
       " 'commercial_invoice': 92255,\n",
       " 'unknown': 25473,\n",
       " 'despatch_note_model_t': 5675,\n",
       " 'packing_list': 5419}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_distribution = {CLASSES[key]: value for key, value in Counter(Y).items()}\n",
    "data_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating holdout test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:56:00.135389Z",
     "start_time": "2020-08-17T13:55:59.853604Z"
    }
   },
   "outputs": [],
   "source": [
    "X, X_holdout, Y, Y_holdout = split_dataset(\n",
    "    X, Y, test_size=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:56:00.141279Z",
     "start_time": "2020-08-17T13:56:00.136514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 27677, 3: 11644, 5: 7642, 1: 1626, 2: 3263, 4: 1702})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(Y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data | `BALANCED_SAME`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:56:27.317888Z",
     "start_time": "2020-08-17T13:56:00.141994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing commercial_invoice...\n",
      "Processing packing_list...\n",
      "Processing delivery_note...\n",
      "Processing customs_summary_declaration_with_commercial_detail_export...\n",
      "Processing despatch_note_model_t...\n",
      "Processing unknown...\n"
     ]
    }
   ],
   "source": [
    "X_balanced_same, Y_balanced_same = balance_dataset(X, Y, CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:56:27.341527Z",
     "start_time": "2020-08-17T13:56:27.328688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3793, 1: 3793, 2: 3793, 3: 3793, 4: 3793, 5: 3793})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(Y_balanced_same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data | `BALANCED_UNKNOWN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:56:55.139862Z",
     "start_time": "2020-08-17T13:56:27.342301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing commercial_invoice...\n",
      "Processing packing_list...\n",
      "Processing delivery_note...\n",
      "Processing customs_summary_declaration_with_commercial_detail_export...\n",
      "Processing despatch_note_model_t...\n",
      "Processing unknown...\n"
     ]
    }
   ],
   "source": [
    "X_balanced_unknown, Y_balanced_unknown = balance_dataset(\n",
    "    X, Y, CLASSES, weights=[1, 1, 1, 1, 1, 2]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:56:55.202657Z",
     "start_time": "2020-08-17T13:56:55.151370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3793, 1: 3793, 2: 3793, 3: 3793, 4: 3793, 5: 7586})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(Y_balanced_unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split | `UNBALANCED`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:56:55.332167Z",
     "start_time": "2020-08-17T13:56:55.208390Z"
    }
   },
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = split_dataset(\n",
    "    X, Y, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split | `BALANCED_SAME`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:56:55.685350Z",
     "start_time": "2020-08-17T13:56:55.333119Z"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    features_train_balanced_same,\n",
    "    features_test_balanced_same,\n",
    "    labels_train_balanced_same,\n",
    "    labels_test_balanced_same,\n",
    ") = split_dataset(X_balanced_same, Y_balanced_same, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split | `BALANCED_UNKNOWN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-17T13:56:56.083352Z",
     "start_time": "2020-08-17T13:56:55.686280Z"
    }
   },
   "outputs": [],
   "source": [
    "(\n",
    "    features_train_balanced_unknown,\n",
    "    features_test_balanced_unknown,\n",
    "    labels_train_balanced_unknown,\n",
    "    labels_test_balanced_unknown,\n",
    ") = split_dataset(X_balanced_unknown, Y_balanced_unknown, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `UNBALANCED`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-17T13:55:43.935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=24)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=24)]: Done   2 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=24)]: Done   9 out of  50 | elapsed:  1.6min remaining:  7.4min\n",
      "[Parallel(n_jobs=24)]: Done  15 out of  50 | elapsed:  4.1min remaining:  9.7min\n",
      "[Parallel(n_jobs=24)]: Done  21 out of  50 | elapsed:  5.2min remaining:  7.1min\n",
      "[Parallel(n_jobs=24)]: Done  27 out of  50 | elapsed:  5.4min remaining:  4.6min\n",
      "[Parallel(n_jobs=24)]: Done  33 out of  50 | elapsed:  6.0min remaining:  3.1min\n",
      "[Parallel(n_jobs=24)]: Done  39 out of  50 | elapsed:  6.6min remaining:  1.9min\n"
     ]
    }
   ],
   "source": [
    "grid_output_svc = test_classifier(\n",
    "    features_train,\n",
    "    labels_train,\n",
    "    max_df_range=(0.5, 1),\n",
    "    min_df_range=(1,10),\n",
    "    k_range=(5000, 50000),\n",
    "    ngram_max=3,\n",
    "    clf=LinearSVC(class_weight=\"balanced\", max_iter=10000),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BALANCED_SAME`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-17T13:55:43.938Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_output_svc_balanced_same = test_classifier(\n",
    "    features_train_balanced_same,\n",
    "    labels_train_balanced_same,\n",
    "    max_df_range=(0.5, 1),\n",
    "    min_df_range=(1,10),\n",
    "    k_range=(5000, 50000),\n",
    "    ngram_max=3,\n",
    "    clf=LinearSVC(max_iter=10000),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BALANCED_UNKNOWN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-17T13:55:43.943Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_output_svc_balanced_unknown = test_classifier(\n",
    "    features_train_balanced_unknown,\n",
    "    labels_train_balanced_unknown,\n",
    "    max_df_range=(0.5, 1),\n",
    "    min_df_range=(1,10),\n",
    "    k_range=(5000, 50000),\n",
    "    ngram_max=3,\n",
    "    clf=LinearSVC(class_weight=\"balanced\", max_iter=10000),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-17T13:55:43.947Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"pkls_best\"):\n",
    "    os.makedirs(\"pkls_best\")\n",
    "save_vars(grid_output_svc, \"./pkls_best/grid_output_svc.pkl\")\n",
    "save_vars(grid_output_svc_balanced_same, \"./pkls_best/grid_output_svc_balanced_same.pkl\")\n",
    "save_vars(grid_output_svc_balanced_unknown, \"./pkls_best/grid_output_svc_balanced_unknown.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-17T13:55:43.950Z"
    }
   },
   "outputs": [],
   "source": [
    "# svc = get_vars(\"grid_output_svc_best.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-17T13:55:43.953Z"
    }
   },
   "outputs": [],
   "source": [
    "model_unbalanced = grid_output_svc.best_estimator_\n",
    "model_balanced_same = grid_output_svc_balanced_same.best_estimator_\n",
    "model_balanced_unknown = grid_output_svc_balanced_unknown.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `UNBALANCED`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-17T13:55:43.956Z"
    }
   },
   "outputs": [],
   "source": [
    "get_clf_results(grid_output_svc, features_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BALANCED_SAME`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-17T13:55:43.961Z"
    }
   },
   "outputs": [],
   "source": [
    "get_clf_results(grid_output_svc_balanced_same, features_test_balanced_same, labels_test_balanced_same)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BALANCED_UNKNOWN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-17T13:55:43.964Z"
    }
   },
   "outputs": [],
   "source": [
    "get_clf_results(grid_output_svc_balanced_unknown, features_test_balanced_unknown, labels_test_balanced_unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docs and labels for each document type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-17T13:55:43.967Z"
    }
   },
   "outputs": [],
   "source": [
    "invoice_docs, invoice_labels = get_samples_of_type(\n",
    "    X_holdout, Y_holdout, 0, CLASSES\n",
    ")\n",
    "packing_docs, packing_labels = get_samples_of_type(\n",
    "    X_holdout, Y_holdout, 1, CLASSES\n",
    ")\n",
    "delivery_docs, delivery_labels = get_samples_of_type(\n",
    "    X_holdout, Y_holdout, 2, CLASSES\n",
    ")\n",
    "customs_docs, customs_labels = get_samples_of_type(\n",
    "    X_holdout, Y_holdout, 3, CLASSES\n",
    ")\n",
    "despatch_docs, despatch_labels = get_samples_of_type(\n",
    "    X_holdout, Y_holdout, 4, CLASSES\n",
    ")\n",
    "unknown_docs, unknown_labels = get_samples_of_type(\n",
    "    X_holdout, Y_holdout, 5, CLASSES\n",
    ")\n",
    "\n",
    "type_dict = {\n",
    "    \"invoice\": (invoice_docs, invoice_labels),\n",
    "    \"packing\": (packing_docs, packing_labels),\n",
    "    \"delivery\": (delivery_docs, delivery_labels),\n",
    "    \"customs\": (customs_docs, customs_labels),\n",
    "    \"despatch\": (despatch_docs, despatch_labels),\n",
    "    \"unknown\": (unknown_docs, unknown_labels),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results for each document type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-17T13:55:43.971Z"
    }
   },
   "outputs": [],
   "source": [
    "model_names = [\"model_unbalanced\", \"model_balanced_same\", \"model_balanced_unknown\"]\n",
    "models = [model_unbalanced, model_balanced_same, model_balanced_unknown]\n",
    "document_names = [\n",
    "    \"commercial_invoice\",\n",
    "    \"packing_list\",\n",
    "    \"delivery_note\",\n",
    "    \"customs_summary\",\n",
    "    \"despatch_note\",\n",
    "    \"unknown\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-17T13:55:43.974Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_models(models, model_names, document_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
